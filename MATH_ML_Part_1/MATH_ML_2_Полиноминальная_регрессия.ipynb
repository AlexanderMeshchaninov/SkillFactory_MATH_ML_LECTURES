{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Images/ml_2.png'>\n",
    "\n",
    "Для начала составим обычную матрицу наблюдений A, расположив векторы в столбцах. Обратите внимание, что вектор из 1 мы не будем добавлять в матрицу (за нас это сделает генератор полиномиальных признаков):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  4],\n",
       "       [ 3,  4,  5],\n",
       "       [-2,  5,  2],\n",
       "       [ 1, -2,  2],\n",
       "       [ 5,  4,  6],\n",
       "       [13, 11,  8],\n",
       "       [ 1,  3, -1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1,3,-2,1,5,13,1],\n",
    "    [3,4,5,-2,4,11,3],\n",
    "    [4,5,2,2,6,8,-1]\n",
    "]).T\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем импортируем класс PolynomialFeatures из библиотеки sklearn. Создадим объект этого класса, указав при инициализации степень полинома равной 2. Также укажем, что нам нужна генерация столбца из 1 (параметр include_bias=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только вызвать метод fit_transform() от имени этого объекта и передать в него нашу матрицу наблюдений A. Для удобства выведем результат в виде DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4      5      6      7     8     9\n",
       "0  1.0   1.0   3.0  4.0    1.0    3.0    4.0    9.0  12.0  16.0\n",
       "1  1.0   3.0   4.0  5.0    9.0   12.0   15.0   16.0  20.0  25.0\n",
       "2  1.0  -2.0   5.0  2.0    4.0  -10.0   -4.0   25.0  10.0   4.0\n",
       "3  1.0   1.0  -2.0  2.0    1.0   -2.0    2.0    4.0  -4.0   4.0\n",
       "4  1.0   5.0   4.0  6.0   25.0   20.0   30.0   16.0  24.0  36.0\n",
       "5  1.0  13.0  11.0  8.0  169.0  143.0  104.0  121.0  88.0  64.0\n",
       "6  1.0   1.0   3.0 -1.0    1.0    3.0   -1.0    9.0  -3.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_poly = poly.fit_transform(A)\n",
    "display(pd.DataFrame(A_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица $A_{\\text{poly}}$, описание столбцов:\n",
    "\n",
    "- **Столбец 0** — единичный, он отвечает за слагаемое с нулевой степенью полинома (любое число в степени $0$ даёт единицу).\n",
    "- **Столбцы 1, 2 и 3** — это наши исходные признаки (векторы $x_1, x_2$ и $x_3$).\n",
    "- **Столбцы 4, 5 и 6** — произведения первого столбца со всеми столбцами:  \n",
    "  $x_1 \\cdot x_1$, $x_1 \\cdot x_2$, $x_1 \\cdot x_3$ соответственно.\n",
    "- **Столбцы 7 и 8** — произведения второго столбца со столбцами 2 и 3:  \n",
    "  $x_2 \\cdot x_2$, $x_2 \\cdot x_3$.\n",
    "- **Столбец 9** — произведение третьего столбца с самим собой:  \n",
    "  $x_3 \\cdot x_3 = x_3^2$.\n",
    "\n",
    "---\n",
    "\n",
    "Таким образом, при генерации полиномиальных признаков объект `PolynomialFeatures` сначала создаёт исходные факторы, затем умножает каждый из них на все факторы и повторяет процедуру. При этом, если комбинация $x_i \\cdot x_j$ уже была сгенерирована ранее, то комбинация $x_j \\cdot x_i$ не рассматривается.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь построим модель полиномиальной регрессии на реальных данных.\n",
    "\n",
    "Возьмём все те же данные о стоимости жилья в районах Бостона. Будем использовать следующие четыре признака: LSTAT, CRIM, PTRATIO и RM. С их помощью мы построим полиномиальную регрессию от первой до пятой степени включительно, а затем сравним результаты по значению средней абсолютной процентной ошибки (MAPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не дублировать код, объявим функцию polynomial_regression(). Она будет принимать на вход матрицу наблюдений, вектор ответов и степень полинома, а возвращать матрицу с полиномиальными признаками, вектор предсказаний и коэффициенты регрессии, найденные по МНК:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Math_algorithms import polynomial_regression\n",
    "\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE']\n",
    "# 'header=None' указывает, что в файле нет строки заголовков, и мы задаем имена столбцов вручную\n",
    "# 'delimiter=r\"\\s+\"' указывает на то, что разделителем в файле являются пробелы (или любые пробелы)\n",
    "# 'names=column_names' задаёт имена столбцов из списка 'column_names'\n",
    "boston_data = pd.read_csv('Data/housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "display(boston_data.head(5))\n",
    "\n",
    "# Делим выборку\n",
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM', 'CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "A_poly1, y_pred1, w_hat1 = polynomial_regression(A, y, 1)\n",
    "A_poly2, y_pred2, w_hat2 = polynomial_regression(A, y, 2)\n",
    "A_poly3, y_pred3, w_hat3 = polynomial_regression(A, y, 3)\n",
    "A_poly4, y_pred4, w_hat4 = polynomial_regression(A, y, 4)\n",
    "A_poly5, y_pred5, w_hat5 = polynomial_regression(A, y, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество построенных регрессий, вычислив метрику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома 1-й степени 18.20%\n",
      "MAPE для полинома 2-й степени  13.41%\n",
      "MAPE для полинома 3-й степени  12.93%\n",
      "MAPE для полинома 4-й степени  10.74%\n",
      "MAPE для полинома 5-й степени  425.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    " \n",
    "print('MAPE для полинома 1-й степени {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred1)*100))\n",
    "print('MAPE для полинома 2-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred2)*100))\n",
    "print('MAPE для полинома 3-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred3)*100))\n",
    "print('MAPE для полинома 4-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred4)*100))\n",
    "print('MAPE для полинома 5-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred5)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиномиальная регрессия первой степени (линейная регрессия) показывает наименьшее качество предсказания, так как зависимость между факторами и целевым признаком нелинейная. С повышением степени полинома процентная ошибка на обучающей выборке вроде бы падает, однако для полинома пятой степени она резко возрастает. Это означает, что модель вообще не описывает зависимость в исходных данных — её прогноз не имеет никакого отношения к действительности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерес представляет полином 5 степени, разобраться почему процент такой резко высокий, поможет объяснение ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>409.591413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12248.037174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-70520.884813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.028490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.434758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>116177.366878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRICE\n",
       "count     126.000000\n",
       "mean      409.591413\n",
       "std     12248.037174\n",
       "min    -70520.884813\n",
       "25%        -1.028490\n",
       "50%         0.000006\n",
       "75%         0.434758\n",
       "max    116177.366878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(w_hat5).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в степенях минимального и максимального коэффициентов явно что-то не так — коэффициенты слишком огромные (исчисляются миллионами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте взглянем на корреляционную матрицу для факторов, на которых мы строим полином пятой степени. Корреляцию со столбцом из единиц считать бессмысленно, поэтому мы не будем его рассматривать. Для удобства расчёта матрицы корреляций обернём матрицу  в DataFrame и воспользуемся методом corr():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 110\n",
      "Количество факторов: 125\n"
     ]
    }
   ],
   "source": [
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly5[:, 1:]).corr()\n",
    "\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly5[:, 1:].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы нашли корень проблемы: ранг корреляционной матрицы — 110, в то время как общее количество факторов (не считая единичного столбца) — 125, то есть ранг корреляционной матрицы не максимален. Это значит, что в корреляционной матрице присутствуют единичные корреляции, а в исходной матрице — линейно зависимые столбцы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, заметим, что, например, для полинома четвёртой степени ранг матрицы корреляций максимален, то есть равен количеству факторов (не включая единичный столбец):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 69\n",
      "Количество факторов: 69\n"
     ]
    }
   ],
   "source": [
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly4[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly4[:, 1:].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому и коэффициенты регрессии полинома четвёртой степени находятся в адекватных пределах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-50.809065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>886.564118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6918.586311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.187936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.322202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2304.941937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRICE\n",
       "count    70.000000\n",
       "mean    -50.809065\n",
       "std     886.564118\n",
       "min   -6918.586311\n",
       "25%      -0.187936\n",
       "50%      -0.000796\n",
       "75%       0.322202\n",
       "max    2304.941937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(w_hat4).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим, что будет, если использовать для построения полиномиальной регрессии реализацию из библиотеки sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома степени 1 — 18.20%, СКО — 2\n",
      "MAPE для полинома степени 2 — 13.41%, СКО — 5\n",
      "MAPE для полинома степени 3 — 12.93%, СКО — 9\n",
      "MAPE для полинома степени 4 — 10.74%, СКО — 304\n",
      "MAPE для полинома степени 5 — 8.98%, СКО — 290\n"
     ]
    }
   ],
   "source": [
    "from Math_algorithms import polynomial_regression_sk\n",
    "\n",
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM', 'CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "for k in range(1, 6):\n",
    "    A_poly, y_pred, w_hat = polynomial_regression_sk(A, y, k)\n",
    "    print(\n",
    "        \"MAPE для полинома степени {} — {:.2f}%, СКО — {:.0f}\".format(\n",
    "            k, mean_absolute_percentage_error(y, y_pred)*100, w_hat.std()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«магия» sklearn — построение полинома пятой степени прошло успешно.\n",
    "\n",
    "Секрет в том, что в sklearn для построения линейной регрессии используется не сама матрица наблюдений A, а её сингулярное разложение, которое гарантированно является невырожденным — из него исключаются линейно зависимые факторы, но такие данные могут быть сомнительными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание: Чем выше степень полинома, тем выше шанс переобучения!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог: \n",
    "\n",
    "- Модель полиномиальной регрессии — более общий случай линейной регрессии, в котором зависимость целевой переменной от факторов нелинейная.\n",
    "\n",
    "- Поиск коэффициентов полинома аналогичен линейной регрессии — решение неоднородной СЛАУ.\n",
    "\n",
    "- Возможна ситуация, когда какие-то сгенерированные полиномиальные факторы могут линейно выражаться через другие факторы. Тогда ранг корреляционной матрицы будет меньше числа факторов и поиск по классическому МНК-алгоритму не будет успешным.\n",
    "\n",
    "- В sklearn для решения последней проблемы предусмотрена защита — использование сингулярного разложения матрицы A. Однако данная защита не решает проблемы неустойчивости коэффициентов регрессии.\n",
    "\n",
    "- Полиномиальная регрессия имеет сильную склонность к переобучению: чем выше степень полинома, тем сложнее модель и выше риск переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построена модель полиномиальной регрессии следующего вида:\n",
    "\n",
    "$$\n",
    "y = 10.4 + 8 \\cdot x_1 + 0.5 \\cdot x_2 + 3 \\cdot x_1^2 + 0.4 \\cdot x_2^2 + 0 \\cdot x_1 x_2\n",
    "$$\n",
    "\n",
    "Поступило новое наблюдение, которое характеризуется вектором:\n",
    "\n",
    "$$\n",
    "x_{\\text{new}} = \\begin{pmatrix} x_{1\\text{new}} \\\\ x_{2\\text{new}} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 4 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Сделайте прогноз целевой переменной с помощью полученной полиномиальной регрессии.  \n",
    "Ответ **округлите до первого знака после точки-разделителя**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.8\n"
     ]
    }
   ],
   "source": [
    "x_new = np.array([1,4])\n",
    "# x_new[0] = 1 (x_1)\n",
    "# x_new[1] = 4 (x_2)\n",
    "y = (10.4 + 8 * x_new[0] + 0.5 * x_new[1] + 3 * x_new[0]**2 + 0.4 * x_new[1]**2 + 0 * x_new[0] * x_new[1])\n",
    "print(y.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью классического МНК найдите коэффициенты полиномиальной регрессии, если используется полином второй степени и задан фактор $\\vec{x}$ и целевая переменная $\\vec{y}$:\n",
    "\n",
    "$$\n",
    "\\vec{y} = w_0 + w_1 \\vec{x} + w_2 \\vec{x}^2\n",
    "$$\n",
    "\n",
    "Где:\n",
    "\n",
    "$$\n",
    "\\vec{x} =\n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "-2 \\\\\n",
    "9\n",
    "\\end{pmatrix}, \\quad\n",
    "\\vec{y} =\n",
    "\\begin{pmatrix}\n",
    "3 \\\\\n",
    "7 \\\\\n",
    "-5 \\\\\n",
    "21\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "В качестве ответа приведите координаты вектора коэффициентов $w_0$, $w_1$, $w_2$, **округлив их до первого знака после точки-разделителя**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1]\n",
      " [ 1  3  9]\n",
      " [ 1 -2 -4]\n",
      " [ 1  9 81]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'w_0:0.1, w_1:2.5, w_2:-0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1,1,1,1],\n",
    "    [1,3,-2,9],\n",
    "    [1**2,3**2,-2**2,9**2]\n",
    "    ]).T\n",
    "\n",
    "print(A)\n",
    "\n",
    "y = np.array([3,7,-5,21])\n",
    "\n",
    "w_hat = np.linalg.inv(A.T @ A) @ A.T @ y\n",
    "w_0 = w_hat[0]\n",
    "w_1 = w_hat[1]\n",
    "w_2 = w_hat[2]\n",
    "display(f'w_0:{w_0:.1f}, w_1:{w_1:.1f}, w_2:{w_2:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель полиномиальной регрессии третьей степени. Будем использовать данные о жилье в Бостоне и возьмём следующие четыре признака: LSTAT, CRIM, PTRATIO и RM.\n",
    "\n",
    "Для оценки качества модели будем использовать кросс-валидацию и сравнивать среднее значение метрики на тренировочных и валидационных фолдах. Кросс-валидацию организуем с помощью функции cross_validate из модуля model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики используем среднюю абсолютную процентную ошибку — MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.64 %\n",
      "MAPE на валидационных фолдах: 24.16 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# Добавляем полиноминальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# Создаем модель линейной регрессии\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Оцениваем модель на кросс-валидации, метрика - МАРЕ\n",
    "cv_results = cross_validate(\n",
    "    lr, # Модель линейной регрессии\n",
    "    X, # Факторы\n",
    "    y, # Целевая переменная\n",
    "    scoring='neg_mean_absolute_percentage_error', # метрика\n",
    "    cv=5, # 5 фолдов\n",
    "    return_train_score=True # Возвращаем результаты валидации\n",
    "    )\n",
    "\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы видим? Даже при, казалось бы, небольшой, третьей степени полинома мы получили переобучение: на тренировочной выборке MAPE=12.64%, а вот на тестовой — MAPE=24.16%. Показатели качества отличаются практически в два раза, что говорит о высоком разбросе модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы справиться с этой ситуацией мы и воспользуемся методом регуляризации.\n",
    "\n",
    "Регуляризация — это способ уменьшения переобучения моделей машинного обучения путём намеренного увеличения смещения модели для уменьшения её разброса.\n",
    "\n",
    "Регуляризация для линейной регрессии преследует сразу несколько целей. Однако далее мы увидим, что все эти цели на самом деле взаимосвязаны:\n",
    "\n",
    "- предотвратить переобучение модели;\n",
    "- включить в функцию потерь штраф за переобучение;\n",
    "- обеспечить существование обратной матрицы $(A^T A)^-1$;\n",
    "- не допустить огромных коэффициентов модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Большие значения весов — прямое свидетельство переобучения модели линейной регрессии и её нестабильности. Идея регуляризации состоит в наложении ограничения на вектор весов (часто говорят — наложение штрафа за высокие веса). В качестве штрафа принято использовать норму вектора весов.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 - RIDGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что матрица $A^T A$ вырождена: её второй и третий столбцы являются пропорциональными с коэффициентом 2. Значит, наша классическая формула МНК  (без сингулярного разложения) не сработает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "# A = np.array([\n",
    "#     [1, 1, 1, 1, 1],\n",
    "#     [1, 0, -3, 2, 4],\n",
    "#     [2, 0, -6, 4, 8]\n",
    "# ]).T\n",
    "\n",
    "# # вектор целевого признака\n",
    "# y = np.array([4, 3, -4, 2, 7])\n",
    "# # получаем оценку коэффициентов регрессии по МНК\n",
    "# w_hat = np.linalg.inv(A.T @ A) @ A.T @ y\n",
    "# print(w_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ожидаемо получили ошибку, говорящую о том, что матрица A вырождена. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем найти вектор оценок весов w ridge по формуле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "\n",
    "# единичная матрица\n",
    "E = np.eye(3)\n",
    "\n",
    "# коэффициент регуляризации\n",
    "alpha = 5\n",
    "\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T @ A + alpha * E) @ A.T @ y\n",
    "print(w_hat_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За реализацию линейной регрессии с $L_2$-регуляризацией в sklearn отвечает класс Ridge. Основной параметр модели, на который стоит обратить внимание — alpha, коэффициент регуляризации из формулы Тихонова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим модель для решения нашей последней задачи, а затем проверим коэффициенты регрессии. Так как мы заранее заложили в матрицу A столбец из единиц, то, чтобы получить корректное решение, параметр fit_intercept следует установить в значение False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "ridge = Ridge(alpha=5, fit_intercept=False)\n",
    "ridge.fit(A, y)\n",
    "\n",
    "# Результаты коэффициентов\n",
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили тот же самый результат, что и раньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, посмотрим, как регуляризация поможет побороть переобучение модели полиномиальной регрессии на наборе данных о домах в Бостоне. Используем те же самые признаки: LSTAT, CRIM, PTRATIO и RM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу cтоит отметить, что для успешной сходимости численных методов оптимизации, которые используются для решения задачи условной оптимизации, необходима стандартизация (нормализация) исходных данных, которая не требовалась для аналитического МНК в классической линейной регрессии (LinearRegression).\n",
    "\n",
    "Примечание: Здесь под стандартизацией понимается именно приведение распределения признака к нулевому среднему и единичному стандартному отклонению (StandardScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся моделью полиномиальной регрессии третьей степени с регуляризацией Тихонова (коэффициент регуляризации возьмём равным 20) и проверим её качество на кросс-валидации по метрике MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.54 %\n",
      "MAPE на валидационных фолдах: 17.02 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L2-регуляризацией\n",
    "ridge = Ridge(alpha=20, solver='svd')\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(ridge, \n",
    "                            X, \n",
    "                            y, \n",
    "                            scoring='neg_mean_absolute_percentage_error', \n",
    "                            cv=5, \n",
    "                            return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось уменьшить ошибку (MAPE) на валидационных фолдах кросс-валидации с 24.16% до 17.02% и сократить разницу в метриках, тем самым уменьшив разброс ответов модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислите коэффициенты линейной регрессии с \\( L_2 \\)-регуляризацией, используя аналитическую формулу Тихонова, если:\n",
    "\n",
    "$$\n",
    "\\vec{x}_1 =\n",
    "\\begin{pmatrix}\n",
    "5 \\\\\n",
    "9 \\\\\n",
    "4 \\\\\n",
    "3 \\\\\n",
    "5\n",
    "\\end{pmatrix}, \\quad\n",
    "\\vec{x}_2 =\n",
    "\\begin{pmatrix}\n",
    "15 \\\\\n",
    "18 \\\\\n",
    "18 \\\\\n",
    "19 \\\\\n",
    "19\n",
    "\\end{pmatrix}, \\quad\n",
    "\\vec{x}_3 =\n",
    "\\begin{pmatrix}\n",
    "7 \\\\\n",
    "6 \\\\\n",
    "7 \\\\\n",
    "7 \\\\\n",
    "7\n",
    "\\end{pmatrix}, \\quad\n",
    "\\vec{y} =\n",
    "\\begin{pmatrix}\n",
    "24 \\\\\n",
    "22 \\\\\n",
    "35 \\\\\n",
    "33 \\\\\n",
    "36\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Коэффициент регуляризации (alpha = 1).\n",
    "\n",
    "---\n",
    "\n",
    "В качестве ответа приведите значения полученных коэффициентов линейной регрессии, **округлив их до второго знака после точки-разделителя**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09\n",
      "-1.71\n",
      "1.91\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1,1,1,1,1],\n",
    "    [5,9,4,3,5],\n",
    "    [15,18,18,19,19],\n",
    "    [7,6,7,7,7]\n",
    "]).T\n",
    "\n",
    "# вектор целевого признака\n",
    "y = np.array([24,22,35,33,36])\n",
    "\n",
    "# единичная матрица\n",
    "E = np.eye(4)\n",
    "\n",
    "# коэффициент регуляризации\n",
    "alpha = 1\n",
    "\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T @ A + alpha * E) @ A.T @ y\n",
    "print(w_hat_ridge[0].round(2))\n",
    "print(w_hat_ridge[1].round(2))\n",
    "print(w_hat_ridge[2].round(2))\n",
    "print(w_hat_ridge[3].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 - LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn $L_1$-регуляризация реализована в классе Lasso, а оптимизационная задача решается алгоритмом координатного спуска (Coordinate Descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как работает Lasso на примере:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем найти коэффициенты регрессии с помощью $L_1$-регуляризации. Для этого подадим нашу матрицу наблюдений A и вектор целевого признака $\\hat{y}$ в модель Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4,3,-4,2,7])\n",
    "\n",
    "# получаем оценку коэффициентов регрессии с помощью L1-регуляризации\n",
    "lasso = Lasso(alpha=0.1, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "\n",
    "# Получаем коэффициенты\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте применим $L_1$-регуляризацию к нашей полиномиальной модели третьей степени, прогнозирующей типичную цену на дома в районах Бостона.\n",
    "\n",
    "Так как метод координатного спуска, который применяется для поиска коэффициентов, является численным, то необходима стандартизация исходных данных, чтобы обеспечить ему сходимость. Возьмём в качестве коэффициента регуляризации $alpha = 0.1$ и проверим качество полученной модели с помощью кросс-валидации по метрике MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.44 %\n",
      "MAPE на валидационных фолдах: 16.44 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L1-регуляризацией\n",
    "lasso = Lasso(alpha=0.1, max_iter=10_000)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(\n",
    "    lasso,\n",
    "    X,\n",
    "    y,\n",
    "    scoring='neg_mean_absolute_percentage_error',\n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что с помощью $L_1$-регуляризации удалось уменьшить ошибку модели (MAPE) на валидационных фолдах с 24.16% до 16.44% и сократить разницу в метриках на тренировочных и валидационных фолдах даже лучше, чем с этим справилась $L_2$-регуляризация. Однако на самом деле мы просто удачно выбрали коэффициент регуляризации — при других значениях могли получиться совершенно другие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELASTIC-NET (Комбинация регуляризации L-1 и L-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn эластичная сетка реализована в классе ElasticNet из пакета с линейными моделями — linear_model. За коэффициент $\\alpha$ отвечает параметр alpha, за коэффициент $\\lambda$ — L1_ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые рекомендации от разработчиков ElasticNet:\n",
    "\n",
    "1. Использование параметра l1_ratio < 0.01 приводит к нестабильным результатам!\n",
    "2. Вместо использования ElasticNet с alpha=0 лучше используйте LinearRegression, так как там применяется аналитическое решение, которое позволяет получать более точные решения, чем численный координатный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример работы с Elastic-Net, а затем применим эту модель к нашей задаче о домах в Бостоне."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим задачу с тремя комбинациями коэффициентов регуляризации:\n",
    "\n",
    "1. $\\alpha$ = 0.1, $\\lambda$ = 0.2\n",
    "2. $\\alpha$ = 0.1, $\\lambda$ = 0.7\n",
    "3. $\\alpha$ = 0.1, $\\lambda$ = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случай 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13492457 0.19525842 0.6237965 ]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "\n",
    "# получаем оценку коэффициентов регрессии\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.2, fit_intercept=False)\n",
    "elastic_net.fit(A, y)\n",
    "\n",
    "# Получаем коэффициенты\n",
    "print(elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что зануления коэффициентов коллинеарных факторов $x_1$ и $x_2$ не произошло. Каждый из них вошёл в уравнение регрессии с ненулевым коэффициентом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случай 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14379753 0.         0.71993025]\n"
     ]
    }
   ],
   "source": [
    "# получаем оценку коэффициентов регрессии\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.7, fit_intercept=False)\n",
    "elastic_net.fit(A, y)\n",
    "\n",
    "# Получаем коэффициенты\n",
    "print(elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание, что произошло зануление коэффициентов. Это неспроста, так как мы понизили влияние $L_2$-регуляризации и одновременно повысили влияние $L_1$-регуляризации, которая, как мы уже знаем, приводит к исключению линейно зависимых факторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случай 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "# получаем оценку коэффициентов регрессии\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=1, fit_intercept=False)\n",
    "elastic_net.fit(A, y)\n",
    "\n",
    "# Получаем коэффициенты\n",
    "print(elastic_net.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В округлениях значения не заметно, однако если присмотреться к коэффициентам более внимательно, можно увидеть, что мы получили в точности те же значения, которые получали для модели Lasso в примере № 2. Неудивительно, ведь мы обнулили влияние $L_2$-регуляризации, выставив l1_ratio=1. По сути, мы использовали чистую модель Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возникает вопрос: какой набор коэффициентов линейной регрессии всё-таки подходит лучше?\n",
    "\n",
    "Ответить на него можно, только вычислив метрику качества и сравнив ошибки прогнозов каждой из полученных моделей!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только попробовать применить Elastic-Net к данным о недвижимости в Бостоне.\n",
    "\n",
    "Как и для других моделей с регуляризацией, для Elastic-Net также лучше заранее позаботиться о стандартизации данных. В качестве коэффициентов регуляризации возьмём $\\alpha$=0.1, $\\lambda$=0.5. Качество модели проверим с помощью кросс-валидации на пяти фолдах, метрика — MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.65 %\n",
      "MAPE на валидационных фолдах: 15.70 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L1- и L2-регуляризациями\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(\n",
    "    elastic_net, \n",
    "    X, \n",
    "    y, \n",
    "    scoring='neg_mean_absolute_percentage_error', \n",
    "    cv=5, \n",
    "    return_train_score=True\n",
    "    )\n",
    "\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, Elastic-Net позволил нам уменьшить значение MAPE на валидационных фолдах с 24.16% до 15.7%. Отличный результат! Он получился лучше, чем у моделей Ridge и Lasso, но опять же, так бывает не всегда."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике при использовании моделей с регуляризацией стоит подбирать значения коэффициентов регуляризации с помощью методов подбора гиперпараметров. Только после подбора гиперпараметров можно сделать вывод, какая из моделей показывает наилучшие результаты для решения конкретной задачи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
